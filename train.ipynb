{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5dedc780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f8219c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date   Value   label\n",
      "0   20160911  621.65  609.67\n",
      "1   20160912  609.67  610.92\n",
      "2   20160913  610.92  608.82\n",
      "3   20160914  608.82  610.38\n",
      "4   20160915  610.38  609.11\n",
      "5   20160916  609.11  607.04\n",
      "6   20160917  607.04  611.58\n",
      "7   20160918  611.58  610.19\n",
      "8   20160919  610.19  608.66\n",
      "9   20160920  608.66  598.88\n",
      "10  20160921  598.88  597.42\n",
      "11  20160922  597.42  594.08\n",
      "12  20160923  594.08  603.88\n",
      "13  20160924  603.88  601.74\n",
      "14  20160925  601.74  598.98\n",
      "15  20160926  598.98  605.96\n",
      "16  20160927  605.96  605.67\n",
      "17  20160928  605.67  603.85\n",
      "18  20160929  603.85  609.39\n",
      "19  20160930  609.39  614.82\n",
      "20  20161001  614.82  612.98\n",
      "21  20161002  612.98  611.85\n",
      "22  20161003  611.85  609.62\n",
      "23  20161004  609.62  607.18\n",
      "24  20161005  607.18  612.08\n",
      "25  20161006  612.08  617.21\n",
      "26  20161007  617.21  614.74\n",
      "27  20161008  614.74  615.65\n",
      "28  20161009  615.65     NaN\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_excel('test1.xlsx')\n",
    "df.columns = ['Date', 'Value']\n",
    "pre_days=1\n",
    "df['label']=df['Value'].shift(-pre_days)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "52e0c65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.17987399]\n",
      " [ 0.20688501]\n",
      " [ 0.4127478 ]\n",
      " [ 0.06689831]\n",
      " [ 0.32381507]\n",
      " [ 0.11465848]\n",
      " [-0.22625031]\n",
      " [ 0.52144335]\n",
      " [ 0.29252393]\n",
      " [ 0.04054787]\n",
      " [-1.5701226 ]\n",
      " [-1.81057034]\n",
      " [-2.36063571]\n",
      " [-0.74667144]\n",
      " [-1.09910854]\n",
      " [-1.55365358]\n",
      " [-0.40411576]\n",
      " [-0.45187592]\n",
      " [-0.75161215]\n",
      " [ 0.16077174]\n",
      " [ 1.0550397 ]\n",
      " [ 0.75200967]\n",
      " [ 0.56590971]\n",
      " [ 0.19865049]\n",
      " [-0.20319367]\n",
      " [ 0.60378846]\n",
      " [ 1.44864936]\n",
      " [ 1.04186448]\n",
      " [ 1.19173259]]\n"
     ]
    }
   ],
   "source": [
    "scaler=StandardScaler()           \n",
    "sca_X=scaler.fit_transform(df.iloc[:,1:-1])\n",
    "print(sca_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "176e7603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "19\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "mem_his_days=10\n",
    "deq=deque(maxlen=mem_his_days)\n",
    "X = []\n",
    "for i in sca_X:\n",
    "    deq.append(i)\n",
    "    if len(deq)==mem_his_days:\n",
    "        X.append(list(deq))\n",
    "\n",
    "X_lately=X[-pre_days:]    \n",
    "X=X[:-pre_days]\n",
    "print(len(X_lately))\n",
    "print(len(X))\n",
    "\n",
    "y=df['label'].values[mem_his_days-1:-pre_days]\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5885e90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "X=np.array(X)\n",
    "y=np.array(y)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "540e1e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5bbd4527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84a5850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9f670acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17 samples, validate on 2 samples\n",
      "Epoch 1/250\n",
      "17/17 [==============================] - 1s 72ms/step - loss: 607.6363 - mape: 100.0000 - val_loss: 603.0762 - val_mape: 99.9994\n",
      "Epoch 2/250\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 607.6332 - mape: 99.9995 - val_loss: 603.0734 - val_mape: 99.9989\n",
      "Epoch 3/250\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 607.6306 - mape: 99.9990 - val_loss: 603.0706 - val_mape: 99.9984\n",
      "Epoch 4/250\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 607.6277 - mape: 99.9986 - val_loss: 603.0677 - val_mape: 99.9980\n",
      "Epoch 5/250\n",
      "17/17 [==============================] - 0s 995us/step - loss: 607.6263 - mape: 99.9983 - val_loss: 603.0648 - val_mape: 99.9975\n",
      "Epoch 6/250\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 607.6250 - mape: 99.9981 - val_loss: 603.0618 - val_mape: 99.9970\n",
      "Epoch 7/250\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 607.6190 - mape: 99.9971 - val_loss: 603.0588 - val_mape: 99.9965\n",
      "Epoch 8/250\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 607.6147 - mape: 99.9964 - val_loss: 603.0555 - val_mape: 99.9959\n",
      "Epoch 9/250\n",
      "17/17 [==============================] - 0s 997us/step - loss: 607.6111 - mape: 99.9958 - val_loss: 603.0522 - val_mape: 99.9954\n",
      "Epoch 10/250\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 607.6080 - mape: 99.9953 - val_loss: 603.0488 - val_mape: 99.9948\n",
      "Epoch 11/250\n",
      "17/17 [==============================] - 0s 939us/step - loss: 607.6083 - mape: 99.9954 - val_loss: 603.0452 - val_mape: 99.9942\n",
      "Epoch 12/250\n",
      "17/17 [==============================] - 0s 821us/step - loss: 607.6004 - mape: 99.9941 - val_loss: 603.0415 - val_mape: 99.9936\n",
      "Epoch 13/250\n",
      "17/17 [==============================] - 0s 880us/step - loss: 607.5958 - mape: 99.9933 - val_loss: 603.0377 - val_mape: 99.9930\n",
      "Epoch 14/250\n",
      "17/17 [==============================] - 0s 821us/step - loss: 607.5937 - mape: 99.9930 - val_loss: 603.0338 - val_mape: 99.9923\n",
      "Epoch 15/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 607.5884 - mape: 99.9921 - val_loss: 603.0297 - val_mape: 99.9916\n",
      "Epoch 16/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 607.5903 - mape: 99.9924 - val_loss: 603.0254 - val_mape: 99.9909\n",
      "Epoch 17/250\n",
      "17/17 [==============================] - 0s 821us/step - loss: 607.5816 - mape: 99.9910 - val_loss: 603.0210 - val_mape: 99.9902\n",
      "Epoch 18/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 607.5786 - mape: 99.9905 - val_loss: 603.0165 - val_mape: 99.9895\n",
      "Epoch 19/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 607.5768 - mape: 99.9902 - val_loss: 603.0117 - val_mape: 99.9887\n",
      "Epoch 20/250\n",
      "17/17 [==============================] - 0s 821us/step - loss: 607.5746 - mape: 99.9898 - val_loss: 603.0068 - val_mape: 99.9879\n",
      "Epoch 21/250\n",
      "17/17 [==============================] - 0s 880us/step - loss: 607.5685 - mape: 99.9888 - val_loss: 603.0016 - val_mape: 99.9870\n",
      "Epoch 22/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 607.5612 - mape: 99.9876 - val_loss: 602.9962 - val_mape: 99.9861\n",
      "Epoch 23/250\n",
      "17/17 [==============================] - 0s 821us/step - loss: 607.5534 - mape: 99.9863 - val_loss: 602.9906 - val_mape: 99.9852\n",
      "Epoch 24/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 607.5522 - mape: 99.9861 - val_loss: 602.9846 - val_mape: 99.9842\n",
      "Epoch 25/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 607.5535 - mape: 99.9864 - val_loss: 602.9784 - val_mape: 99.9832\n",
      "Epoch 26/250\n",
      "17/17 [==============================] - 0s 821us/step - loss: 607.5388 - mape: 99.9839 - val_loss: 602.9718 - val_mape: 99.9821\n",
      "Epoch 27/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 607.5462 - mape: 99.9851 - val_loss: 602.9650 - val_mape: 99.9809\n",
      "Epoch 28/250\n",
      "17/17 [==============================] - 0s 762us/step - loss: 607.5178 - mape: 99.9805 - val_loss: 602.9576 - val_mape: 99.9797\n",
      "Epoch 29/250\n",
      "17/17 [==============================] - 0s 880us/step - loss: 607.5297 - mape: 99.9824 - val_loss: 602.9499 - val_mape: 99.9784\n",
      "Epoch 30/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 607.5024 - mape: 99.9779 - val_loss: 602.9417 - val_mape: 99.9771\n",
      "Epoch 31/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 607.4960 - mape: 99.9769 - val_loss: 602.9329 - val_mape: 99.9756\n",
      "Epoch 32/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 607.5041 - mape: 99.9782 - val_loss: 602.9235 - val_mape: 99.9740\n",
      "Epoch 33/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 607.4815 - mape: 99.9745 - val_loss: 602.9135 - val_mape: 99.9724\n",
      "Epoch 34/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 607.4913 - mape: 99.9761 - val_loss: 602.9028 - val_mape: 99.9706\n",
      "Epoch 35/250\n",
      "17/17 [==============================] - 0s 821us/step - loss: 607.4553 - mape: 99.9702 - val_loss: 602.8912 - val_mape: 99.9687\n",
      "Epoch 36/250\n",
      "17/17 [==============================] - 0s 821us/step - loss: 607.4474 - mape: 99.9689 - val_loss: 602.8788 - val_mape: 99.9666\n",
      "Epoch 37/250\n",
      "17/17 [==============================] - 0s 821us/step - loss: 607.4429 - mape: 99.9681 - val_loss: 602.8654 - val_mape: 99.9644\n",
      "Epoch 38/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 607.4335 - mape: 99.9666 - val_loss: 602.8510 - val_mape: 99.9620\n",
      "Epoch 39/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 607.4114 - mape: 99.9630 - val_loss: 602.8351 - val_mape: 99.9594\n",
      "Epoch 40/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 607.4009 - mape: 99.9612 - val_loss: 602.8179 - val_mape: 99.9565\n",
      "Epoch 41/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 607.3828 - mape: 99.9583 - val_loss: 602.7991 - val_mape: 99.9534\n",
      "Epoch 42/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 607.4100 - mape: 99.9626 - val_loss: 602.7787 - val_mape: 99.9500\n",
      "Epoch 43/250\n",
      "17/17 [==============================] - 0s 821us/step - loss: 607.3357 - mape: 99.9505 - val_loss: 602.7561 - val_mape: 99.9463\n",
      "Epoch 44/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 607.3372 - mape: 99.9507 - val_loss: 602.7311 - val_mape: 99.9421\n",
      "Epoch 45/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 607.2642 - mape: 99.9386 - val_loss: 602.7034 - val_mape: 99.9375\n",
      "Epoch 46/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 607.3156 - mape: 99.9472 - val_loss: 602.6727 - val_mape: 99.9324\n",
      "Epoch 47/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 607.2662 - mape: 99.9390 - val_loss: 602.6383 - val_mape: 99.9267\n",
      "Epoch 48/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 607.2880 - mape: 99.9426 - val_loss: 602.5997 - val_mape: 99.9203\n",
      "Epoch 49/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 607.1912 - mape: 99.9267 - val_loss: 602.5560 - val_mape: 99.9130\n",
      "Epoch 50/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 607.0820 - mape: 99.9087 - val_loss: 602.5066 - val_mape: 99.9048\n",
      "Epoch 51/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 607.1466 - mape: 99.9195 - val_loss: 602.4501 - val_mape: 99.8954\n",
      "Epoch 52/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 607.0035 - mape: 99.8957 - val_loss: 602.3850 - val_mape: 99.8846\n",
      "Epoch 53/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 606.9180 - mape: 99.8817 - val_loss: 602.3096 - val_mape: 99.8720\n",
      "Epoch 54/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 606.7967 - mape: 99.8616 - val_loss: 602.2222 - val_mape: 99.8575\n",
      "Epoch 55/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 606.9784 - mape: 99.8917 - val_loss: 602.1194 - val_mape: 99.8404\n",
      "Epoch 56/250\n",
      "17/17 [==============================] - 0s 821us/step - loss: 606.5496 - mape: 99.8204 - val_loss: 601.9999 - val_mape: 99.8205\n",
      "Epoch 57/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 606.4210 - mape: 99.7992 - val_loss: 601.8569 - val_mape: 99.7966\n",
      "Epoch 58/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 606.4741 - mape: 99.8086 - val_loss: 601.6832 - val_mape: 99.7677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 605.6907 - mape: 99.6784 - val_loss: 601.4775 - val_mape: 99.7334\n",
      "Epoch 60/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 605.4849 - mape: 99.6450 - val_loss: 601.2249 - val_mape: 99.6913\n",
      "Epoch 61/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 604.8480 - mape: 99.5383 - val_loss: 600.9163 - val_mape: 99.6398\n",
      "Epoch 62/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 604.7188 - mape: 99.5167 - val_loss: 600.5287 - val_mape: 99.5751\n",
      "Epoch 63/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 604.0342 - mape: 99.4047 - val_loss: 600.0413 - val_mape: 99.4937\n",
      "Epoch 64/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 603.8795 - mape: 99.3777 - val_loss: 599.4218 - val_mape: 99.3902\n",
      "Epoch 65/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 601.3222 - mape: 98.9555 - val_loss: 598.6608 - val_mape: 99.2631\n",
      "Epoch 66/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 602.5324 - mape: 99.1579 - val_loss: 597.6926 - val_mape: 99.1013\n",
      "Epoch 67/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 600.2457 - mape: 98.7749 - val_loss: 596.4734 - val_mape: 98.8974\n",
      "Epoch 68/250\n",
      "17/17 [==============================] - 0s 587us/step - loss: 594.9571 - mape: 97.8969 - val_loss: 594.9875 - val_mape: 98.6489\n",
      "Epoch 69/250\n",
      "17/17 [==============================] - 0s 646us/step - loss: 594.6179 - mape: 97.8407 - val_loss: 593.1036 - val_mape: 98.3338\n",
      "Epoch 70/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 593.3733 - mape: 97.6322 - val_loss: 590.7031 - val_mape: 97.9322\n",
      "Epoch 71/250\n",
      "17/17 [==============================] - 0s 806us/step - loss: 584.6436 - mape: 96.1880 - val_loss: 587.7029 - val_mape: 97.4301\n",
      "Epoch 72/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 593.1949 - mape: 97.6215 - val_loss: 583.8966 - val_mape: 96.7929\n",
      "Epoch 73/250\n",
      "17/17 [==============================] - 0s 705us/step - loss: 587.2472 - mape: 96.6222 - val_loss: 579.0828 - val_mape: 95.9868\n",
      "Epoch 74/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 562.8448 - mape: 92.5720 - val_loss: 573.2972 - val_mape: 95.0178\n",
      "Epoch 75/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 570.6900 - mape: 93.8767 - val_loss: 566.1155 - val_mape: 93.8149\n",
      "Epoch 76/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 549.2589 - mape: 90.3270 - val_loss: 558.9253 - val_mape: 92.6106\n",
      "Epoch 77/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 553.7527 - mape: 91.0784 - val_loss: 550.0771 - val_mape: 91.1285\n",
      "Epoch 78/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 546.8655 - mape: 89.9445 - val_loss: 539.5636 - val_mape: 89.3674\n",
      "Epoch 79/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 547.6962 - mape: 90.0861 - val_loss: 528.9227 - val_mape: 87.5850\n",
      "Epoch 80/250\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 557.4612 - mape: 91.7305 - val_loss: 518.9757 - val_mape: 85.9192\n",
      "Epoch 81/250\n",
      "17/17 [==============================] - 0s 997us/step - loss: 518.5498 - mape: 85.3042 - val_loss: 508.1357 - val_mape: 84.1039\n",
      "Epoch 82/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 534.1083 - mape: 87.8583 - val_loss: 497.1270 - val_mape: 82.2604\n",
      "Epoch 83/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 492.4896 - mape: 80.9874 - val_loss: 484.1635 - val_mape: 80.0895\n",
      "Epoch 84/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 519.2261 - mape: 85.3871 - val_loss: 470.3360 - val_mape: 77.7739\n",
      "Epoch 85/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 527.3454 - mape: 86.8366 - val_loss: 456.2154 - val_mape: 75.4095\n",
      "Epoch 86/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 487.9634 - mape: 80.2545 - val_loss: 437.5634 - val_mape: 72.2856\n",
      "Epoch 87/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 529.6752 - mape: 87.1956 - val_loss: 418.4836 - val_mape: 69.0904\n",
      "Epoch 88/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 529.0342 - mape: 87.1502 - val_loss: 398.9477 - val_mape: 65.8193\n",
      "Epoch 89/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 508.0710 - mape: 83.6771 - val_loss: 378.1447 - val_mape: 62.3363\n",
      "Epoch 90/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 487.1113 - mape: 80.2119 - val_loss: 355.7688 - val_mape: 58.5906\n",
      "Epoch 91/250\n",
      "17/17 [==============================] - 0s 681us/step - loss: 497.2821 - mape: 81.9311 - val_loss: 336.1982 - val_mape: 55.3163\n",
      "Epoch 92/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 467.1458 - mape: 76.9272 - val_loss: 317.0590 - val_mape: 52.1151\n",
      "Epoch 93/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 528.7780 - mape: 87.2172 - val_loss: 302.7401 - val_mape: 49.7225\n",
      "Epoch 94/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 529.2430 - mape: 87.2967 - val_loss: 292.6863 - val_mape: 48.0455\n",
      "Epoch 95/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 444.9560 - mape: 73.3312 - val_loss: 285.9122 - val_mape: 46.9188\n",
      "Epoch 96/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 379.5621 - mape: 62.3070 - val_loss: 269.1710 - val_mape: 44.1227\n",
      "Epoch 97/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 418.7160 - mape: 68.9811 - val_loss: 248.8116 - val_mape: 40.7207\n",
      "Epoch 98/250\n",
      "17/17 [==============================] - 0s 680us/step - loss: 445.5870 - mape: 73.3868 - val_loss: 231.6329 - val_mape: 37.8564\n",
      "Epoch 99/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 414.1593 - mape: 68.2709 - val_loss: 235.3338 - val_mape: 38.5015\n",
      "Epoch 100/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 392.8730 - mape: 64.6660 - val_loss: 235.3387 - val_mape: 38.5199\n",
      "Epoch 101/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 277.9557 - mape: 45.5721 - val_loss: 243.0370 - val_mape: 39.8415\n",
      "Epoch 102/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 436.7860 - mape: 72.0070 - val_loss: 252.5381 - val_mape: 41.4678\n",
      "Epoch 103/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 459.5922 - mape: 75.7545 - val_loss: 257.5579 - val_mape: 42.3364\n",
      "Epoch 104/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 368.6093 - mape: 60.8150 - val_loss: 261.6533 - val_mape: 43.0511\n",
      "Epoch 105/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 398.6531 - mape: 65.7033 - val_loss: 259.9003 - val_mape: 42.7725\n",
      "Epoch 106/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 378.0417 - mape: 62.2248 - val_loss: 258.5756 - val_mape: 42.5681\n",
      "Epoch 107/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 356.4122 - mape: 58.7190 - val_loss: 251.5460 - val_mape: 41.3932\n",
      "Epoch 108/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 375.4152 - mape: 61.8626 - val_loss: 241.7874 - val_mape: 39.7540\n",
      "Epoch 109/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 358.6811 - mape: 59.1632 - val_loss: 227.5398 - val_mape: 37.3490\n",
      "Epoch 110/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 298.8380 - mape: 49.1447 - val_loss: 214.1371 - val_mape: 35.0864\n",
      "Epoch 111/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 356.0303 - mape: 58.5511 - val_loss: 203.2988 - val_mape: 33.2600\n",
      "Epoch 112/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 316.1865 - mape: 52.0497 - val_loss: 196.6920 - val_mape: 32.1554\n",
      "Epoch 113/250\n",
      "17/17 [==============================] - 0s 673us/step - loss: 291.2875 - mape: 47.9061 - val_loss: 192.3315 - val_mape: 31.4344\n",
      "Epoch 114/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 299.3448 - mape: 49.1991 - val_loss: 189.7959 - val_mape: 31.0259\n",
      "Epoch 115/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 299.7679 - mape: 49.3474 - val_loss: 186.1703 - val_mape: 30.4330\n",
      "Epoch 116/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 261.8698 - mape: 43.0416 - val_loss: 186.0765 - val_mape: 30.4449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 253.3494 - mape: 41.5501 - val_loss: 188.0347 - val_mape: 30.8090\n",
      "Epoch 118/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 276.4078 - mape: 45.4959 - val_loss: 191.1025 - val_mape: 31.3660\n",
      "Epoch 119/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 338.1305 - mape: 55.7558 - val_loss: 191.8851 - val_mape: 31.5338\n",
      "Epoch 120/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 276.7102 - mape: 45.4958 - val_loss: 193.7567 - val_mape: 31.8927\n",
      "Epoch 121/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 288.1837 - mape: 47.5321 - val_loss: 191.8125 - val_mape: 31.5979\n",
      "Epoch 122/250\n",
      "17/17 [==============================] - 0s 646us/step - loss: 251.2517 - mape: 41.3809 - val_loss: 185.4830 - val_mape: 30.5461\n",
      "Epoch 123/250\n",
      "17/17 [==============================] - 0s 705us/step - loss: 208.7705 - mape: 34.3513 - val_loss: 180.1434 - val_mape: 29.6643\n",
      "Epoch 124/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 259.5066 - mape: 42.7652 - val_loss: 173.7659 - val_mape: 28.6045\n",
      "Epoch 125/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 231.3557 - mape: 38.1347 - val_loss: 165.4855 - val_mape: 27.2137\n",
      "Epoch 126/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 222.4277 - mape: 36.6182 - val_loss: 155.9326 - val_mape: 25.5995\n",
      "Epoch 127/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 225.3733 - mape: 37.1674 - val_loss: 146.8849 - val_mape: 24.0714\n",
      "Epoch 128/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 215.3012 - mape: 35.3059 - val_loss: 138.5314 - val_mape: 22.6610\n",
      "Epoch 129/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 158.1217 - mape: 25.9678 - val_loss: 134.3364 - val_mape: 21.9552\n",
      "Epoch 130/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 178.9051 - mape: 29.3780 - val_loss: 134.6360 - val_mape: 22.0185\n",
      "Epoch 131/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 235.7505 - mape: 38.8065 - val_loss: 125.6881 - val_mape: 20.5428\n",
      "Epoch 132/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 162.4989 - mape: 26.7033 - val_loss: 119.0441 - val_mape: 19.4583\n",
      "Epoch 133/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 251.2249 - mape: 41.2561 - val_loss: 114.9447 - val_mape: 18.7937\n",
      "Epoch 134/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 211.1213 - mape: 34.8046 - val_loss: 111.7912 - val_mape: 18.2923\n",
      "Epoch 135/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 180.7190 - mape: 29.7143 - val_loss: 108.2114 - val_mape: 17.7149\n",
      "Epoch 136/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 163.9156 - mape: 26.9060 - val_loss: 105.2241 - val_mape: 17.2499\n",
      "Epoch 137/250\n",
      "17/17 [==============================] - 0s 646us/step - loss: 189.7509 - mape: 31.2137 - val_loss: 102.5206 - val_mape: 16.8475\n",
      "Epoch 138/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 175.5930 - mape: 28.8489 - val_loss: 98.7189 - val_mape: 16.2680\n",
      "Epoch 139/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 145.2642 - mape: 23.9397 - val_loss: 93.8247 - val_mape: 15.4783\n",
      "Epoch 140/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 140.1532 - mape: 23.1608 - val_loss: 87.5954 - val_mape: 14.4516\n",
      "Epoch 141/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 187.6936 - mape: 30.8756 - val_loss: 81.2360 - val_mape: 13.3646\n",
      "Epoch 142/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 126.6050 - mape: 20.9072 - val_loss: 76.0673 - val_mape: 12.4566\n",
      "Epoch 143/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 116.5289 - mape: 19.2980 - val_loss: 75.0519 - val_mape: 12.2690\n",
      "Epoch 144/250\n",
      "17/17 [==============================] - 0s 821us/step - loss: 118.2148 - mape: 19.4526 - val_loss: 71.7856 - val_mape: 11.7382\n",
      "Epoch 145/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 152.4091 - mape: 25.0771 - val_loss: 77.7184 - val_mape: 12.7285\n",
      "Epoch 146/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 132.1373 - mape: 21.7252 - val_loss: 87.5067 - val_mape: 14.3628\n",
      "Epoch 147/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 96.9008 - mape: 15.9527 - val_loss: 103.0566 - val_mape: 16.9503\n",
      "Epoch 148/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 124.9809 - mape: 20.6081 - val_loss: 110.8143 - val_mape: 18.2441\n",
      "Epoch 149/250\n",
      "17/17 [==============================] - 0s 821us/step - loss: 153.6129 - mape: 25.3086 - val_loss: 102.2708 - val_mape: 16.8358\n",
      "Epoch 150/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 120.5056 - mape: 19.8109 - val_loss: 94.5205 - val_mape: 15.5603\n",
      "Epoch 151/250\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 98.3662 - mape: 16.2186 - val_loss: 96.6501 - val_mape: 15.9223\n",
      "Epoch 152/250\n",
      "17/17 [==============================] - 0s 821us/step - loss: 143.1258 - mape: 23.6943 - val_loss: 89.6229 - val_mape: 14.7721\n",
      "Epoch 153/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 111.6744 - mape: 18.3669 - val_loss: 93.6855 - val_mape: 15.4474\n",
      "Epoch 154/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 105.1534 - mape: 17.2205 - val_loss: 94.7453 - val_mape: 15.6280\n",
      "Epoch 155/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 110.6599 - mape: 18.2932 - val_loss: 93.5407 - val_mape: 15.4322\n",
      "Epoch 156/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 102.1791 - mape: 16.8134 - val_loss: 95.0999 - val_mape: 15.6868\n",
      "Epoch 157/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 103.4974 - mape: 16.9935 - val_loss: 96.1860 - val_mape: 15.8642\n",
      "Epoch 158/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 83.2673 - mape: 13.6348 - val_loss: 100.8354 - val_mape: 16.6336\n",
      "Epoch 159/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 81.5118 - mape: 13.5015 - val_loss: 114.3474 - val_mape: 18.8729\n",
      "Epoch 160/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 54.2555 - mape: 8.9329 - val_loss: 115.5623 - val_mape: 19.0749\n",
      "Epoch 161/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 91.7061 - mape: 15.1146 - val_loss: 110.9384 - val_mape: 18.3096\n",
      "Epoch 162/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 73.6740 - mape: 12.1584 - val_loss: 101.3099 - val_mape: 16.7143\n",
      "Epoch 163/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 153.7776 - mape: 25.3465 - val_loss: 86.6107 - val_mape: 14.2787\n",
      "Epoch 164/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 83.3330 - mape: 13.7434 - val_loss: 74.0435 - val_mape: 12.1976\n",
      "Epoch 165/250\n",
      "17/17 [==============================] - 0s 997us/step - loss: 117.0473 - mape: 19.2070 - val_loss: 60.3003 - val_mape: 9.9209\n",
      "Epoch 166/250\n",
      "17/17 [==============================] - 0s 821us/step - loss: 132.2026 - mape: 21.7785 - val_loss: 57.1689 - val_mape: 9.4047\n",
      "Epoch 167/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 150.6014 - mape: 24.7865 - val_loss: 65.9927 - val_mape: 10.8709\n",
      "Epoch 168/250\n",
      "17/17 [==============================] - 0s 703us/step - loss: 107.1190 - mape: 17.5741 - val_loss: 84.6224 - val_mape: 13.9634\n",
      "Epoch 169/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 110.3040 - mape: 18.2658 - val_loss: 98.5947 - val_mape: 16.2831\n",
      "Epoch 170/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 135.3109 - mape: 22.2220 - val_loss: 108.7989 - val_mape: 17.9790\n",
      "Epoch 171/250\n",
      "17/17 [==============================] - 0s 821us/step - loss: 71.1868 - mape: 11.7360 - val_loss: 118.8674 - val_mape: 19.6522\n",
      "Epoch 172/250\n",
      "17/17 [==============================] - 0s 646us/step - loss: 161.8428 - mape: 26.6998 - val_loss: 123.3083 - val_mape: 20.3919\n",
      "Epoch 173/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 94.6540 - mape: 15.5513 - val_loss: 118.4039 - val_mape: 19.5818\n",
      "Epoch 174/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 83.4900 - mape: 13.7244 - val_loss: 108.7839 - val_mape: 17.9893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 78.2867 - mape: 12.8741 - val_loss: 94.0967 - val_mape: 15.5574\n",
      "Epoch 176/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 170.1228 - mape: 27.9991 - val_loss: 76.6997 - val_mape: 12.6766\n",
      "Epoch 177/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 145.4908 - mape: 23.9807 - val_loss: 71.6945 - val_mape: 11.8498\n",
      "Epoch 178/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 117.7942 - mape: 19.3888 - val_loss: 69.2241 - val_mape: 11.4435\n",
      "Epoch 179/250\n",
      "17/17 [==============================] - 0s 586us/step - loss: 62.7607 - mape: 10.3488 - val_loss: 74.0577 - val_mape: 12.2490\n",
      "Epoch 180/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 94.3376 - mape: 15.4715 - val_loss: 93.0953 - val_mape: 15.4065\n",
      "Epoch 181/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 81.4242 - mape: 13.4531 - val_loss: 114.0367 - val_mape: 18.8802\n",
      "Epoch 182/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 122.7956 - mape: 20.1766 - val_loss: 126.8897 - val_mape: 21.0129\n",
      "Epoch 183/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 95.6440 - mape: 15.7988 - val_loss: 128.5560 - val_mape: 21.2906\n",
      "Epoch 184/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 96.3648 - mape: 15.7993 - val_loss: 119.2513 - val_mape: 19.7490\n",
      "Epoch 185/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 175.8632 - mape: 29.0490 - val_loss: 101.6884 - val_mape: 16.8379\n",
      "Epoch 186/250\n",
      "17/17 [==============================] - 0s 681us/step - loss: 106.3860 - mape: 17.4087 - val_loss: 81.8393 - val_mape: 13.5473\n",
      "Epoch 187/250\n",
      "17/17 [==============================] - 0s 586us/step - loss: 137.0579 - mape: 22.5946 - val_loss: 68.2698 - val_mape: 11.2974\n",
      "Epoch 188/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 86.1396 - mape: 14.2368 - val_loss: 61.3096 - val_mape: 10.1434\n",
      "Epoch 189/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 72.0164 - mape: 11.8327 - val_loss: 67.6548 - val_mape: 11.1959\n",
      "Epoch 190/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 95.2658 - mape: 15.5700 - val_loss: 81.7987 - val_mape: 13.5417\n",
      "Epoch 191/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 76.5337 - mape: 12.5419 - val_loss: 100.3763 - val_mape: 16.6231\n",
      "Epoch 192/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 55.9952 - mape: 9.2122 - val_loss: 118.3573 - val_mape: 19.6058\n",
      "Epoch 193/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 102.9130 - mape: 16.8392 - val_loss: 132.4099 - val_mape: 21.9370\n",
      "Epoch 194/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 158.2704 - mape: 25.9323 - val_loss: 137.9682 - val_mape: 22.8594\n",
      "Epoch 195/250\n",
      "17/17 [==============================] - 0s 646us/step - loss: 139.3929 - mape: 22.8977 - val_loss: 135.9352 - val_mape: 22.5227\n",
      "Epoch 196/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 121.0894 - mape: 19.9914 - val_loss: 125.1111 - val_mape: 20.7282\n",
      "Epoch 197/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 117.2909 - mape: 19.3692 - val_loss: 106.2798 - val_mape: 17.6057\n",
      "Epoch 198/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 79.7559 - mape: 13.1921 - val_loss: 84.9665 - val_mape: 14.0715\n",
      "Epoch 199/250\n",
      "17/17 [==============================] - 0s 587us/step - loss: 52.7191 - mape: 8.6704 - val_loss: 68.6477 - val_mape: 11.3660\n",
      "Epoch 200/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 110.9193 - mape: 18.1857 - val_loss: 57.0051 - val_mape: 9.4361\n",
      "Epoch 201/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 74.4457 - mape: 12.3172 - val_loss: 54.2893 - val_mape: 8.9866\n",
      "Epoch 202/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 101.9754 - mape: 16.7162 - val_loss: 56.6410 - val_mape: 9.3776\n",
      "Epoch 203/250\n",
      "17/17 [==============================] - 0s 587us/step - loss: 79.6986 - mape: 13.1094 - val_loss: 63.3520 - val_mape: 10.4917\n",
      "Epoch 204/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 79.1257 - mape: 12.9836 - val_loss: 70.3278 - val_mape: 11.6490\n",
      "Epoch 205/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 117.8118 - mape: 19.4174 - val_loss: 76.3633 - val_mape: 12.6506\n",
      "Epoch 206/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 93.1542 - mape: 15.3014 - val_loss: 84.5314 - val_mape: 14.0060\n",
      "Epoch 207/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 102.1220 - mape: 16.8134 - val_loss: 96.2285 - val_mape: 15.9466\n",
      "Epoch 208/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 92.4081 - mape: 15.0774 - val_loss: 107.8588 - val_mape: 17.8758\n",
      "Epoch 209/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 121.5456 - mape: 20.0963 - val_loss: 112.2749 - val_mape: 18.6084\n",
      "Epoch 210/250\n",
      "17/17 [==============================] - 0s 700us/step - loss: 143.7084 - mape: 23.7379 - val_loss: 108.2724 - val_mape: 17.9447\n",
      "Epoch 211/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 57.2404 - mape: 9.4651 - val_loss: 102.1136 - val_mape: 16.9231\n",
      "Epoch 212/250\n",
      "17/17 [==============================] - 0s 587us/step - loss: 80.0566 - mape: 13.1018 - val_loss: 95.9178 - val_mape: 15.8959\n",
      "Epoch 213/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 40.5661 - mape: 6.6927 - val_loss: 86.1370 - val_mape: 14.2742\n",
      "Epoch 214/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 142.0785 - mape: 23.3314 - val_loss: 76.3266 - val_mape: 12.6479\n",
      "Epoch 215/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 43.7033 - mape: 7.1905 - val_loss: 75.8154 - val_mape: 12.5638\n",
      "Epoch 216/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 91.1359 - mape: 14.9732 - val_loss: 73.6050 - val_mape: 12.1976\n",
      "Epoch 217/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 65.1533 - mape: 10.6984 - val_loss: 73.9220 - val_mape: 12.2503\n",
      "Epoch 218/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 123.1367 - mape: 20.2225 - val_loss: 77.8349 - val_mape: 12.8994\n",
      "Epoch 219/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 64.6935 - mape: 10.6637 - val_loss: 83.0098 - val_mape: 13.7579\n",
      "Epoch 220/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 163.5115 - mape: 26.8331 - val_loss: 89.9658 - val_mape: 14.9111\n",
      "Epoch 221/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 81.4646 - mape: 13.3819 - val_loss: 92.7870 - val_mape: 15.3783\n",
      "Epoch 222/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 98.7631 - mape: 16.1686 - val_loss: 87.4496 - val_mape: 14.4925\n",
      "Epoch 223/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 103.2067 - mape: 16.9980 - val_loss: 85.6898 - val_mape: 14.1998\n",
      "Epoch 224/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 46.0732 - mape: 7.5965 - val_loss: 90.9227 - val_mape: 15.0668\n",
      "Epoch 225/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 81.5254 - mape: 13.4264 - val_loss: 93.6396 - val_mape: 15.5167\n",
      "Epoch 226/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 82.4384 - mape: 13.5727 - val_loss: 97.2402 - val_mape: 16.1128\n",
      "Epoch 227/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 38.9168 - mape: 6.4193 - val_loss: 103.9068 - val_mape: 17.2169\n",
      "Epoch 228/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 99.1187 - mape: 16.2874 - val_loss: 109.5418 - val_mape: 18.1495\n",
      "Epoch 229/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 77.1922 - mape: 12.7844 - val_loss: 108.8359 - val_mape: 18.0315\n",
      "Epoch 230/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 133.6878 - mape: 22.0120 - val_loss: 103.0455 - val_mape: 17.0701\n",
      "Epoch 231/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 67.4939 - mape: 11.1179 - val_loss: 95.4774 - val_mape: 15.8142\n",
      "Epoch 232/250\n",
      "17/17 [==============================] - 0s 821us/step - loss: 77.4540 - mape: 12.8152 - val_loss: 87.8997 - val_mape: 14.5570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 141.3126 - mape: 23.1626 - val_loss: 80.0337 - val_mape: 13.2521\n",
      "Epoch 234/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 152.3380 - mape: 25.0881 - val_loss: 70.4594 - val_mape: 11.6637\n",
      "Epoch 235/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 37.6988 - mape: 6.2211 - val_loss: 72.5565 - val_mape: 12.0109\n",
      "Epoch 236/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 60.0587 - mape: 9.9018 - val_loss: 85.2414 - val_mape: 14.1146\n",
      "Epoch 237/250\n",
      "17/17 [==============================] - 0s 764us/step - loss: 83.3124 - mape: 13.7041 - val_loss: 96.0699 - val_mape: 15.9105\n",
      "Epoch 238/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 118.7834 - mape: 19.5198 - val_loss: 98.8277 - val_mape: 16.3676\n",
      "Epoch 239/250\n",
      "17/17 [==============================] - 0s 765us/step - loss: 92.9570 - mape: 15.2968 - val_loss: 99.4782 - val_mape: 16.4753\n",
      "Epoch 240/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 102.0756 - mape: 16.8203 - val_loss: 93.0024 - val_mape: 15.4015\n",
      "Epoch 241/250\n",
      "17/17 [==============================] - 0s 645us/step - loss: 65.2713 - mape: 10.7276 - val_loss: 86.3535 - val_mape: 14.2992\n",
      "Epoch 242/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 75.9964 - mape: 12.4872 - val_loss: 81.1467 - val_mape: 13.4361\n",
      "Epoch 243/250\n",
      "17/17 [==============================] - 0s 821us/step - loss: 49.4969 - mape: 8.1385 - val_loss: 72.1150 - val_mape: 11.9388\n",
      "Epoch 244/250\n",
      "17/17 [==============================] - 0s 765us/step - loss: 85.8589 - mape: 14.1506 - val_loss: 66.2712 - val_mape: 10.9699\n",
      "Epoch 245/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 58.7087 - mape: 9.7346 - val_loss: 62.9222 - val_mape: 10.4152\n",
      "Epoch 246/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 68.7352 - mape: 11.2822 - val_loss: 68.2112 - val_mape: 11.2928\n",
      "Epoch 247/250\n",
      "17/17 [==============================] - 0s 704us/step - loss: 94.1075 - mape: 15.5529 - val_loss: 75.3748 - val_mape: 12.4812\n",
      "Epoch 248/250\n",
      "17/17 [==============================] - 0s 763us/step - loss: 189.7024 - mape: 31.3157 - val_loss: 83.3314 - val_mape: 13.8009\n",
      "Epoch 249/250\n",
      "17/17 [==============================] - 0s 765us/step - loss: 101.6448 - mape: 16.7869 - val_loss: 90.6896 - val_mape: 15.0213\n",
      "Epoch 250/250\n",
      "17/17 [==============================] - 0s 819us/step - loss: 103.8692 - mape: 17.1643 - val_loss: 94.6038 - val_mape: 15.6703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x20768f60688>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(12,input_shape=X.shape[1:],activation='relu',return_sequences=True)) \n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(LSTM(12,activation='relu',return_sequences=True)) \n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(LSTM(12,activation='relu')) \n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mae',metrics=['mape'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=250,verbose=1,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acebe002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
